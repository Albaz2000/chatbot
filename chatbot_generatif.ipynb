{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lenovo\\Desktop\\CAPSTONE\\Chatbot generatif\\chatbot_generatif.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/CAPSTONE/Chatbot%20generatif/chatbot_generatif.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/CAPSTONE/Chatbot%20generatif/chatbot_generatif.ipynb#ch0000000?line=1'>2</a>\u001b[0m human_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_table(\u001b[39m\"\u001b[39m\u001b[39mdata/human_text_indo_v2.txt\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/CAPSTONE/Chatbot%20generatif/chatbot_generatif.ipynb#ch0000000?line=2'>3</a>\u001b[0m                            header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/CAPSTONE/Chatbot%20generatif/chatbot_generatif.ipynb#ch0000000?line=3'>4</a>\u001b[0m                            engine\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Desktop/CAPSTONE/Chatbot%20generatif/chatbot_generatif.ipynb#ch0000000?line=4'>5</a>\u001b[0m human_data\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py:135\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/__init__.py?line=116'>117</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomputation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39meval\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/__init__.py?line=118'>119</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/__init__.py?line=119'>120</a>\u001b[0m     concat,\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/__init__.py?line=120'>121</a>\u001b[0m     lreshape,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/__init__.py?line=131'>132</a>\u001b[0m     qcut,\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/__init__.py?line=132'>133</a>\u001b[0m )\n\u001b[1;32m--> <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/__init__.py?line=134'>135</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m api, arrays, errors, io, plotting, testing, tseries\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/__init__.py?line=135'>136</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_print_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/__init__.py?line=137'>138</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/__init__.py?line=138'>139</a>\u001b[0m     \u001b[39m# excel\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/__init__.py?line=139'>140</a>\u001b[0m     ExcelFile,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/__init__.py?line=167'>168</a>\u001b[0m     read_spss,\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/__init__.py?line=168'>169</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\testing.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=0'>1</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=1'>2</a>\u001b[0m \u001b[39mPublic testing utility functions.\u001b[39;00m\n\u001b[0;32m      <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=2'>3</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m----> <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_testing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=6'>7</a>\u001b[0m     assert_extension_array_equal,\n\u001b[0;32m      <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=7'>8</a>\u001b[0m     assert_frame_equal,\n\u001b[0;32m      <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=8'>9</a>\u001b[0m     assert_index_equal,\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=9'>10</a>\u001b[0m     assert_series_equal,\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=10'>11</a>\u001b[0m )\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=12'>13</a>\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=13'>14</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39massert_extension_array_equal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=14'>15</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39massert_frame_equal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=15'>16</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39massert_series_equal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=16'>17</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39massert_index_equal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/testing.py?line=17'>18</a>\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_testing\\__init__.py:979\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/_testing/__init__.py?line=973'>974</a>\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpytest\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/_testing/__init__.py?line=975'>976</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pytest\u001b[39m.\u001b[39mraises(expected_exception, match\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)  \u001b[39m# noqa: PDF010\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/_testing/__init__.py?line=978'>979</a>\u001b[0m cython_table \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mcore\u001b[39m.\u001b[39mcommon\u001b[39m.\u001b[39m_cython_table\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/_testing/__init__.py?line=981'>982</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_cython_table_params\u001b[39m(ndframe, func_names_and_expected):\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/_testing/__init__.py?line=982'>983</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/_testing/__init__.py?line=983'>984</a>\u001b[0m \u001b[39m    Combine frame, functions from com._cython_table\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/_testing/__init__.py?line=984'>985</a>\u001b[0m \u001b[39m    keys and expected result.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/_testing/__init__.py?line=996'>997</a>\u001b[0m \u001b[39m        List of three items (DataFrame, function, expected result)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lenovo/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/_testing/__init__.py?line=997'>998</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "human_data = pd.read_table(\"data/human_text_indo_v2.txt\", \n",
    "                           header=None,\n",
    "                           engine='python')\n",
    "human_data.columns = [\"human\"]\n",
    "robot_data = pd.read_table(\"data/robot_text_indo.txt\",\n",
    "                           header=None,\n",
    "                           engine='python')\n",
    "robot_data.columns = [\"robot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'human':human_data.human, 'robot': robot_data.robot}\n",
    "df = pd.DataFrame(data)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ganti [...] dgn kata hai\n",
    "import re\n",
    "df.human = df.human.apply(lambda x : re.sub(r\"\\[\\w+\\]\", \"hai\", x))\n",
    "df.robot = df.robot.apply(lambda x : re.sub(r\"\\[\\w+\\]\", \"hai\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konversi huruf kecil\n",
    "df.human = df.human.apply(lambda x: x.lower())\n",
    "df.robot = df.robot.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hapus tanda baca\n",
    "import string\n",
    "exclude = set(string.punctuation)\n",
    "df.human = df.human.apply(lambda x : ''.join(ch for ch in x if ch not in exclude))\n",
    "df.robot = df.robot.apply(lambda x : ''.join(ch for ch in x if ch not in exclude))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hapus angka\n",
    "remove_digits = str.maketrans('', '', string.digits)\n",
    "df.human = df.human.apply(lambda x: x.translate(remove_digits))\n",
    "df.robot = df.robot.apply(lambda x: x.translate(remove_digits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hapus emoticon\n",
    "df.human = df.human.apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n",
    "df.robot = df.robot.apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat vocab (human & robot) dari data train\n",
    "vocabulary = set()\n",
    "\n",
    "# menggabungkan robot kolom dgn human kolom\n",
    "for idx, row in df_train.iterrows():\n",
    "    sent = row.human + '' + row.robot\n",
    "    [vocabulary.update(sent.split())]\n",
    "\n",
    "print(f\"Ukuran Vocab : {len(vocabulary)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vocab = []\n",
    "\n",
    "for idx, row in df_train.iterrows():\n",
    "    sent = row.human + '' + row.robot\n",
    "    [all_vocab.append(i) for i in sent.split()]\n",
    "print(f\"Jumlah semua token : {len(all_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masukan token >> vocab >> counter >> membentuk dict. (vocab: frekuensi) >> \n",
    "# ..sort yg lebih dr threshold >> ambil x0 (q dari sorted dict) \n",
    "\n",
    "# hitung frekuensi vocab dan hapus yg tidak perlu (sedikit)\n",
    "from collections import Counter\n",
    "counter = Counter(all_vocab)\n",
    "\n",
    "dic_ = dict(counter)\n",
    "\n",
    "# jika vocab <3 maka tdk dipakai utk proses selanjutnya (eliminasi vocab)\n",
    "# data jumlah vocab diperlukan utk one.dot encoding sblm embedding\n",
    "threshold = 3\n",
    "\n",
    "sorted_dic = sorted(dic_.items(), reverse=True, key = lambda x: x[1])\n",
    "sorted_dic = [x for x in sorted_dic if x[1] > threshold]\n",
    "all_vocab = [x[0] for x in sorted_dic]\n",
    "len(all_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat dictionary word_to_idx & idx_to_word sblm masuk embedding\n",
    "# machine learning hanya bisa ambil angka bukan kata\n",
    "ix = 1\n",
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "\n",
    "# e = kata\n",
    "for e in all_vocab:\n",
    "    word_to_idx[e] = ix\n",
    "    idx_to_word[ix] = e\n",
    "    ix += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data komutatif\n",
    "word_to_idx['nama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_word[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tambahkan \"startseq\" dan \"endseq\" (string awal kalimat dan akhir kalimat)\n",
    "\n",
    "word_to_idx['startseq'] = 846\n",
    "word_to_idx['startseq'] = 847\n",
    "\n",
    "idx_to_word[846] = 'startseq'\n",
    "idx_to_word[847] = 'endseq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update vocab_size\n",
    "vocab_size = len(idx_to_word) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tambahkan startseq & endseq di data training (hanya utk robot >> label)\n",
    "df_train.robot = df.robot.apply(lambda x: 'startseq '+ x + 'endseq')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat generator\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "def data_generator(train_df, word_to_idx, max_len, number_conversation):\n",
    "    x1, x2, y = [], [], []\n",
    "    n = 0\n",
    "    # ekstrak input berasal dari kolom human >> diiterasi >> setiap conversation diubah ke kata ke index\n",
    "    while True:\n",
    "        for idx, row in train_df.iterrows():\n",
    "            seq_human = [ word_to_idx[word] for word in row['human'].split() if word in word_to_idx]\n",
    "            seq_human = pad_sequences([seq_human], maxlen=max_len, value=0, padding='post')[0]\n",
    "            seq_robot = [ word_to_idx[word] for word in row['robot'].split() if word in word_to_idx]\n",
    "\n",
    "            for i in range(1, len(seq_robot)):\n",
    "                in_seq = seq_robot[:i]\n",
    "                out_seq = seq_robot[i]\n",
    "\n",
    "                in_seq = pad_sequences([in_seq], maxlen=max_len, value=0, padding='post')[0]\n",
    "                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\n",
    "                X1.append(seq_human)\n",
    "                X2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "            if n==number_conversation:\n",
    "                # [X1, X2], y\n",
    "                yield([np.array(X1), np.array(X2)], np.array(y))\n",
    "                X2, X2, y = [], [], []\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasample = df_train.sample(2)\n",
    "datagen = data_generator(datasample, word_to_idx, 50, len(datasample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tes generator\n",
    "datasample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training \n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, LSTM, Add\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "max_len = 50\n",
    "input_chat = Input(shape=(max_len,))\n",
    "input_x = Embedding(input_dim=vocab_size, outout_dim=50, mask_zero=True)(input_chat)\n",
    "input_x = Dropout(0.3)(input_x)\n",
    "input_x = LSTM(256)(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_x = Input(shape=(max_len,))\n",
    "output_x = Embedding(input_dim=vocab_size, output_dim=50, mask_zero=True)(output_chat)\n",
    "output_x = Dropout(0.3)(output_x)\n",
    "output_x = LSTM(256)(output_x)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "213524bb45a1aeaf737b1d8c77d7b8db5d425938d9dffc5f4bc6fe6dd3324700"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
